{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T15:41:43.412321Z",
     "start_time": "2020-11-12T15:41:43.401244Z"
    }
   },
   "outputs": [],
   "source": [
    "# Path to the MDS dataset\n",
    "dataset_path='../datasets/MDS/processed_acl/' \n",
    "\n",
    "#### all_domains = ['books', 'dvd', 'electronics', 'kitchen']\n",
    "#### src_domain and trg_domain can be any of the above domains.\n",
    "s_domain = 'books' #source domain\n",
    "t_domain = 'kitchen' #target domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T15:41:44.805118Z",
     "start_time": "2020-11-12T15:41:44.167925Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys,os\n",
    "#### Change \"0\" to GPU device number you want to use if you have multiple GPU devices\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] =\"1\" \n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from aux_functions import get_all_docs, preproces_datasets, SimpleModel, DataHandler, Solver\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T15:42:27.956327Z",
     "start_time": "2020-11-12T15:41:45.812481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 documents read for domain books in file positive.review\n",
      "1000 documents read for domain books in file negative.review\n",
      "4465 documents read for domain books in file unlabeled.review\n",
      "1000 documents read for domain dvd in file positive.review\n",
      "1000 documents read for domain dvd in file negative.review\n",
      "3586 documents read for domain dvd in file unlabeled.review\n",
      "1000 documents read for domain electronics in file positive.review\n",
      "1000 documents read for domain electronics in file negative.review\n",
      "5681 documents read for domain electronics in file unlabeled.review\n",
      "1000 documents read for domain kitchen in file positive.review\n",
      "1000 documents read for domain kitchen in file negative.review\n",
      "5945 documents read for domain kitchen in file unlabeled.review\n",
      "source_docs.shape (2000,) source_labels.shape (2000,) target_docs.shape (7945,) target_labels.shape (7945,)\n",
      "Shapes after unifying features:\n",
      "source.X.shape (2000, 58402) target.X.shape (7945, 58402)\n",
      "Shapes of the inputs that will be fed to the classifier:\n",
      "x_source contains positive and negative reviews from the src domain.\n",
      "x_target contains positive, negative and unlabeled reviews from the trg domain.\n",
      "x_test contains unlabeled reviews from the trg domain. The final accuracy is reported on x_test.\n",
      "x_source.shape (2000, 30000) x_target.shape (7945, 30000) x_test.shape (5945, 30000)\n"
     ]
    }
   ],
   "source": [
    "documents = get_all_docs(dataset_path)\n",
    "x_source,y_source,x_target,y_target,x_test,y_test = preproces_datasets(s_domain,t_domain,documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a model on the src domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T15:42:30.449887Z",
     "start_time": "2020-11-12T15:42:27.957755Z"
    }
   },
   "outputs": [],
   "source": [
    "net = SimpleModel(input_size=x_source.shape[1])\n",
    "if torch.cuda.is_available():\n",
    "    net.cuda()\n",
    "\n",
    "base_lr = 0.0001\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=base_lr)\n",
    "tsolver = Solver(optimizer,net,base_lr)\n",
    "\n",
    "dhandler = DataHandler(x_source,y_source,None,batch_size=128,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T15:42:36.408946Z",
     "start_time": "2020-11-12T15:42:36.392553Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model_on_src(nb_iters,dhandler,tsolver):\n",
    "    st = time.time()\n",
    "    loss = 0\n",
    "    for i in range(nb_iters):\n",
    "        x_batch,y_batch = dhandler.next_batch()\n",
    "        x_batch,y_batch = x_batch.cuda(),y_batch.cuda()\n",
    "        # update learning rate\n",
    "        if i%5==0:\n",
    "            tsolver.iters+=1\n",
    "            tsolver.update_lr()\n",
    "\n",
    "        tsolver.net.train()\n",
    "        tsolver.net.zero_grad()\n",
    "\n",
    "        source_logits, _ = tsolver.net(x_batch)\n",
    "        y_onehot = torch.FloatTensor(len(y_batch), 2).cuda()\n",
    "        y_onehot.zero_()\n",
    "        y_onehot.scatter_(1, y_batch.view(-1,1), 1)\n",
    "        mse_loss = torch.sum((source_logits - y_onehot)**2,dim=1)\n",
    "        mse_loss = torch.mean(mse_loss)\n",
    "        mse_loss.backward()\n",
    "        loss += mse_loss\n",
    "\n",
    "        # update the network\n",
    "        tsolver.optimizer.step()\n",
    "        if i % 50 == 49 or i == nb_iters - 1:\n",
    "\n",
    "            remained_iters = nb_iters - i\n",
    "            passed_time = time.time() - st\n",
    "            ETA = int(passed_time * remained_iters / i)\n",
    "            ETA_min, ETA_sec = ETA // 60, ETA % 60\n",
    "            mean_loss = loss/i\n",
    "            print ('\\r' + \\\n",
    "                  ' iter: ' + str(i + 1) + '/' + str(nb_iters) + \\\n",
    "                  ' ETA: ' + str(ETA_min) + ':' + \"{0:02d}\".format(ETA_sec) + \\\n",
    "                  ' loss: ' + \"{0:0.4f}\".format(mean_loss),end=\" \")\n",
    "            sys.stdout.flush()\n",
    "    print(' ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T15:42:37.426008Z",
     "start_time": "2020-11-12T15:42:37.410271Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_outputs(x,y,tsolver,ret_logits=False):\n",
    "    with torch.no_grad():\n",
    "        tsolver.net.eval()\n",
    "        batch_size = 128\n",
    "        test_handler = DataHandler(x,y,None,batch_size,shuffle=False)\n",
    "        total_batch = test_handler.len//batch_size\n",
    "        if test_handler.len%batch_size!=0:\n",
    "            total_batch+=1\n",
    "\n",
    "        Preds = np.zeros(total_batch*batch_size)\n",
    "        Labels = np.zeros(total_batch*batch_size)\n",
    "        Logits = torch.zeros((total_batch*batch_size,2))\n",
    "        for i in range(total_batch):\n",
    "            x_batch,y_batch = test_handler.next_batch()\n",
    "            x_batch,y_batch = x_batch.cuda(),y_batch.cuda()\n",
    "            pred_logits,pred_probs = tsolver.net(x_batch)\n",
    "            Preds[i*batch_size:(i+1)*batch_size] = pred_probs.cpu().numpy().argmax(axis=1)\n",
    "            if ret_logits:\n",
    "                Logits[i*batch_size:(i+1)*batch_size] = pred_logits.cpu()\n",
    "            Labels[i*batch_size:(i+1)*batch_size] = y_batch.cpu().numpy()\n",
    "        if ret_logits:\n",
    "            Logits = Logits[:len(x)]\n",
    "            return Logits\n",
    "        Preds = Preds[:len(x)]\n",
    "        Labels = Labels[:len(x)]\n",
    "        return Preds,Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T15:42:38.192408Z",
     "start_time": "2020-11-12T15:42:38.141805Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(x,y,tsolver):\n",
    "    Preds,Labels = get_outputs(x,y,tsolver)\n",
    "    return np.sum(Preds==Labels)/len(Preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T15:43:03.174436Z",
     "start_time": "2020-11-12T15:42:38.876260Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " iter: 100/100 ETA: 0:00 loss: 0.3924  \n",
      " iter: 100/100 ETA: 0:00 loss: 0.0016  \n",
      " iter: 100/100 ETA: 0:00 loss: 0.0001  \n",
      " iter: 100/100 ETA: 0:00 loss: 0.0000  \n",
      " iter: 100/100 ETA: 0:00 loss: 0.0000  \n",
      " iter: 100/100 ETA: 0:00 loss: 0.0000  \n",
      " iter: 100/100 ETA: 0:00 loss: 0.0000  \n",
      " iter: 100/100 ETA: 0:00 loss: 0.0000  \n",
      " iter: 100/100 ETA: 0:00 loss: 0.0000  \n",
      " iter: 100/100 ETA: 0:00 loss: 0.0000  \n",
      "accuracy on source:  1.0\n",
      "accuracy on target:  0.7524229074889868\n",
      "accuracy on test:  0.7530698065601346\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    train_model_on_src(100,dhandler,tsolver)\n",
    "    \n",
    "current_acc = test(x_source,y_source,tsolver)\n",
    "print('accuracy on source: ',current_acc)\n",
    "current_acc = test(x_target,y_target,tsolver)\n",
    "print('accuracy on target: ',current_acc)\n",
    "only_src_acc = test(x_test,y_test,tsolver)\n",
    "print('accuracy on test: ',only_src_acc) ### This is the accuracy model gets on the reviews that are names \"unlabaled\" in target domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Domain Adaptation with PPPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T15:43:03.190959Z",
     "start_time": "2020-11-12T15:43:03.176769Z"
    }
   },
   "outputs": [],
   "source": [
    "base_lr = 0.0001*0.25\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=base_lr)\n",
    "tsolver = Solver(optimizer,net,base_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T15:43:03.301859Z",
     "start_time": "2020-11-12T15:43:03.199514Z"
    }
   },
   "outputs": [],
   "source": [
    "trg_gts = y_target\n",
    "trg_data = x_target\n",
    "src_gts = y_source\n",
    "src_data = x_source\n",
    "t_labels = np.array(trg_gts)\n",
    "\n",
    "n_classes = 2\n",
    "trg_cp = np.zeros(n_classes)\n",
    "for i in range(n_classes):\n",
    "    trg_cp[i] = np.sum(t_labels==i)/len(t_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T15:43:03.422336Z",
     "start_time": "2020-11-12T15:43:03.303981Z"
    }
   },
   "outputs": [],
   "source": [
    "def adjust_pseudo_labels(trg_probs_np,trg_cp):\n",
    "    n_classes = 2\n",
    "    pseudo_labels = trg_probs_np.argmax(axis=1)\n",
    "    current_cp = np.zeros(n_classes)\n",
    "    for c in range(n_classes):\n",
    "        current_cp[c] = np.sum(pseudo_labels==c)/len(trg_probs_np)\n",
    "\n",
    "    diff_class_rates =  current_cp - trg_cp\n",
    "    for i in range(len(diff_class_rates)):\n",
    "        if diff_class_rates[i]<=0:\n",
    "            continue\n",
    "        predicted_as_c = pseudo_labels==i\n",
    "        current_class = i\n",
    "        current_diff = diff_class_rates[i]\n",
    "        current_num = np.round(current_diff*len(trg_probs_np)).astype(np.int32)\n",
    "\n",
    "        current_probs = trg_probs_np[pseudo_labels==current_class]\n",
    "        current_probs_sorted = np.sort(current_probs,axis=1)\n",
    "        current_certainty_scores = current_probs_sorted[:,-1] - current_probs_sorted[:,-2]\n",
    "        \n",
    "        current_certainty_scores_sorted_inds = np.argsort(current_certainty_scores)\n",
    "        y_val = np.ones(len(current_certainty_scores))*current_class\n",
    "        for i in range(current_num):\n",
    "            y_val[i]=-1\n",
    "        temp_pl = np.zeros(len(current_certainty_scores))\n",
    "        temp_pl[current_certainty_scores_sorted_inds] = y_val\n",
    "        pseudo_labels[predicted_as_c] = temp_pl\n",
    "    \n",
    "    return pseudo_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T15:43:03.522650Z",
     "start_time": "2020-11-12T15:43:03.429806Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model_with_weights(nb_epochs,dhandler,tsolver):\n",
    "    total_batch = dhandler.len // dhandler.batch_size\n",
    "    if dhandler.len % dhandler.batch_size != 0:\n",
    "        total_batch += 1\n",
    "    st = time.time()\n",
    "    for ep in range(nb_epochs):\n",
    "        loss = 0\n",
    "        for i in range(total_batch):\n",
    "            x_batch,y_batch,w_batch = dhandler.next_batch()\n",
    "            x_batch,y_batch,w_batch = x_batch.cuda(),y_batch.cuda(),w_batch.cuda()\n",
    "            if i%5==0:\n",
    "                tsolver.iters+=1\n",
    "                tsolver.update_lr()\n",
    "            tsolver.net.train()\n",
    "            tsolver.net.zero_grad()\n",
    "            source_logits, _ = tsolver.net(x_batch)\n",
    "\n",
    "            y_onehot = torch.FloatTensor(len(y_batch), 2).cuda()\n",
    "            y_onehot.zero_()\n",
    "            y_onehot.scatter_(1, y_batch.view(-1,1), 1)\n",
    "            mse_loss = torch.sum((source_logits - y_onehot)**2,dim=1)*w_batch\n",
    "            mse_loss = torch.mean(mse_loss)\n",
    "            mse_loss.backward()\n",
    "            loss += mse_loss\n",
    "\n",
    "            # update the network\n",
    "            tsolver.optimizer.step()\n",
    "        passed_time = time.time() - st\n",
    "        remained_epochs = nb_epochs - ep\n",
    "        ETA = int(passed_time * remained_epochs)\n",
    "        ETA_min, ETA_sec = ETA // 60, ETA % 60\n",
    "        print ('\\r' + 'epoch: ' + str(ep + 1) + '/' + str(nb_epochs) + \\\n",
    "                      ' ETA: ' + str(ETA_min) + ':' + \"{0:02d}\".format(ETA_sec) + \\\n",
    "                      ' loss: ' + \"{0:0.4f}\".format(loss/total_batch),end=\" \")\n",
    "        sys.stdout.flush()\n",
    "    print(' ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T15:50:08.430107Z",
     "start_time": "2020-11-12T15:50:08.409611Z"
    }
   },
   "outputs": [],
   "source": [
    "def DA(tsolver,src_data,src_gts,trg_data,trg_cp,x_test,y_test):\n",
    "    begin_time = time.time()\n",
    "    inner_loop_size = 1\n",
    "    trg_gts_unreal = torch.zeros(len(trg_data))\n",
    "    weights_src = torch.ones(len(src_gts))\n",
    "    \n",
    "    for nnn in range(0,90,2):\n",
    "        if nnn>=88:\n",
    "            inner_loop_size=10\n",
    "        for j in range(inner_loop_size):\n",
    "            print ('^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i:',nnn//2 + 1,'j:',j,\n",
    "               'Elapsed Time(m): {0:0.2f}'.format((time.time()-begin_time)/60))\n",
    "            \n",
    "\n",
    "            #### Get scores on the target domain\n",
    "            trg_scores = get_outputs(trg_data,trg_gts_unreal,tsolver,ret_logits=True)\n",
    "            trg_scores_np = trg_scores.cpu().numpy()\n",
    "            \n",
    "            #### Calculate pseudo-labels of the target domain\n",
    "            trg_pseudo_labels = trg_scores_np.argmax(axis=1)\n",
    "            \n",
    "            ### Calculate the certainty scores for target samples\n",
    "            trg_scores_np_sorted = np.sort(trg_scores_np,axis=1)\n",
    "            certainty_scores = trg_scores_np_sorted[:,-1] - trg_scores_np_sorted[:,-2]\n",
    "            \n",
    "            ### Calculate weight for the target samples\n",
    "            weights_trg = np.zeros(len(certainty_scores))\n",
    "            for c in range(n_classes):\n",
    "                predicted_as_c = trg_pseudo_labels==c\n",
    "                size_c = np.sum(predicted_as_c)\n",
    "                if size_c>1:\n",
    "                    left_size = int(np.ceil(((nnn+1)*0.01+0.1)*size_c))\n",
    "                    x_val_left = 1+(10/2 - 1)/left_size*(np.arange(left_size))\n",
    "                    right_size = size_c - left_size\n",
    "                    x_val_right = 10000*(np.arange(1,right_size+1))\n",
    "                    x_val = np.concatenate((x_val_left,x_val_right))\n",
    "                    y_val = np.power(x_val,-1)\n",
    "                    y_val = y_val[::-1]\n",
    "\n",
    "                    cs_c = certainty_scores[predicted_as_c]\n",
    "                    cs_c_sorted_inds = np.argsort(cs_c)\n",
    "                    weights_trg2 = np.zeros(len(cs_c))\n",
    "                    weights_trg2[cs_c_sorted_inds] = y_val\n",
    "                    weights_trg[predicted_as_c] = weights_trg2\n",
    "                    \n",
    "                    \n",
    "            ### Exclude\n",
    "            trg_pseudo_labels_adjusted = adjust_pseudo_labels(np.copy(trg_scores_np),trg_cp)\n",
    "            coef = (trg_pseudo_labels==trg_pseudo_labels_adjusted)*1\n",
    "            weights_trg*=coef\n",
    "            weights_trg = weights_trg.astype(np.float32)\n",
    "            weights_trg = torch.tensor(weights_trg)\n",
    "\n",
    "\n",
    "            trg_pseudo_labels = trg_pseudo_labels.astype(np.int32)\n",
    "            trg_pseudo_labels = torch.tensor(trg_pseudo_labels,dtype=torch.long)\n",
    "            \n",
    "            #### Randomly select some samples from the source domain\n",
    "            p = np.random.permutation(len(src_data))\n",
    "            p = p[:len(trg_data)*2]\n",
    "            x_temp = src_data[p]\n",
    "            y_temp = src_gts[p]\n",
    "            w_temp = weights_src[:len(trg_data)*2]\n",
    "            \n",
    "            #### Train Model\n",
    "            m1 = torch.cat((x_temp,trg_data))\n",
    "            m2 = torch.cat((y_temp,trg_pseudo_labels))\n",
    "            m3 = torch.cat((w_temp,weights_trg))\n",
    "            DA_dhandler = DataHandler(m1, m2, m3, 64,shuffle=True)\n",
    "            ep = 1\n",
    "            train_model_with_weights(ep,DA_dhandler,tsolver)\n",
    "\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                current_acc = test(x_test,y_test,tsolver)\n",
    "                print('current accuracy on test set: ',current_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T15:48:03.735385Z",
     "start_time": "2020-11-12T15:43:03.681474Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 1 j: 0 Elapsed Time(m): 0.00\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0005  \n",
      "current accuracy on test set:  0.7720773759461732\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 2 j: 0 Elapsed Time(m): 0.09\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0003  \n",
      "current accuracy on test set:  0.7826745164003364\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 3 j: 0 Elapsed Time(m): 0.18\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0002  \n",
      "current accuracy on test set:  0.7902439024390244\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 4 j: 0 Elapsed Time(m): 0.27\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0001  \n",
      "current accuracy on test set:  0.7991589571068124\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 5 j: 0 Elapsed Time(m): 0.37\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0001  \n",
      "current accuracy on test set:  0.8057190916736754\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 6 j: 0 Elapsed Time(m): 0.46\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0001  \n",
      "current accuracy on test set:  0.8116063919259883\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 7 j: 0 Elapsed Time(m): 0.55\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0001  \n",
      "current accuracy on test set:  0.8131202691337258\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 8 j: 0 Elapsed Time(m): 0.64\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0001  \n",
      "current accuracy on test set:  0.8148023549201009\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 9 j: 0 Elapsed Time(m): 0.74\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0001  \n",
      "current accuracy on test set:  0.8185029436501261\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 10 j: 0 Elapsed Time(m): 0.83\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0001  \n",
      "current accuracy on test set:  0.8235492010092514\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 11 j: 0 Elapsed Time(m): 0.92\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0001  \n",
      "current accuracy on test set:  0.8233809924306139\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 12 j: 0 Elapsed Time(m): 1.01\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0001  \n",
      "current accuracy on test set:  0.8302775441547519\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 13 j: 0 Elapsed Time(m): 1.11\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0001  \n",
      "current accuracy on test set:  0.8353238015138772\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 14 j: 0 Elapsed Time(m): 1.19\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0001  \n",
      "current accuracy on test set:  0.8378469301934399\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 15 j: 0 Elapsed Time(m): 1.29\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0000  \n",
      "current accuracy on test set:  0.840201850294365\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 16 j: 0 Elapsed Time(m): 1.38\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0000  \n",
      "current accuracy on test set:  0.8427249789739276\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 17 j: 0 Elapsed Time(m): 1.47\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0000  \n",
      "current accuracy on test set:  0.8417157275021027\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 18 j: 0 Elapsed Time(m): 1.56\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0000  \n",
      "current accuracy on test set:  0.8328006728343146\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 19 j: 0 Elapsed Time(m): 1.66\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0000  \n",
      "current accuracy on test set:  0.8248948696383516\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 20 j: 0 Elapsed Time(m): 1.75\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0000  \n",
      "current accuracy on test set:  0.8208578637510513\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 21 j: 0 Elapsed Time(m): 1.85\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0000  \n",
      "current accuracy on test set:  0.8126156433978133\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 22 j: 0 Elapsed Time(m): 1.94\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0000  \n",
      "current accuracy on test set:  0.8116063919259883\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 23 j: 0 Elapsed Time(m): 2.04\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0000  \n",
      "current accuracy on test set:  0.8159798149705635\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 24 j: 0 Elapsed Time(m): 2.13\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0000  \n",
      "current accuracy on test set:  0.8259041211101766\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 25 j: 0 Elapsed Time(m): 2.22\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0000  \n",
      "current accuracy on test set:  0.8346509671993272\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 26 j: 0 Elapsed Time(m): 2.31\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0000  \n",
      "current accuracy on test set:  0.8460891505466779\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 27 j: 0 Elapsed Time(m): 2.40\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0000  \n",
      "current accuracy on test set:  0.8479394449116905\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 28 j: 0 Elapsed Time(m): 2.50\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0000  \n",
      "current accuracy on test set:  0.8518082422203532\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 29 j: 0 Elapsed Time(m): 2.59\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0000  \n",
      "current accuracy on test set:  0.8538267451640034\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 30 j: 0 Elapsed Time(m): 2.69\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0000  \n",
      "current accuracy on test set:  0.856349873843566\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 31 j: 0 Elapsed Time(m): 2.78\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0000  \n",
      "current accuracy on test set:  0.8546677880571909\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 32 j: 0 Elapsed Time(m): 2.87\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0000  \n",
      "current accuracy on test set:  0.8548359966358284\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 33 j: 0 Elapsed Time(m): 2.96\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0000  \n",
      "current accuracy on test set:  0.8539949537426409\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 34 j: 0 Elapsed Time(m): 3.06\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0000  \n",
      "current accuracy on test set:  0.8529857022708158\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 35 j: 0 Elapsed Time(m): 3.15\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0000  \n",
      "current accuracy on test set:  0.847098402018503\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 36 j: 0 Elapsed Time(m): 3.24\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0000  \n",
      "current accuracy on test set:  0.8440706476030277\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 37 j: 0 Elapsed Time(m): 3.33\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0000  \n",
      "current accuracy on test set:  0.8390243902439024\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 38 j: 0 Elapsed Time(m): 3.43\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0000  \n",
      "current accuracy on test set:  0.8328006728343146\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 39 j: 0 Elapsed Time(m): 3.52\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0000  \n",
      "current accuracy on test set:  0.830950378469302\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 40 j: 0 Elapsed Time(m): 3.62\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0000  \n",
      "current accuracy on test set:  0.8344827586206897\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 41 j: 0 Elapsed Time(m): 3.71\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0000  \n",
      "current accuracy on test set:  0.8396972245584525\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 42 j: 0 Elapsed Time(m): 3.81\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0000  \n",
      "current accuracy on test set:  0.8509671993271657\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 43 j: 0 Elapsed Time(m): 3.90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/1 ETA: 0:02 loss: 0.0002  \n",
      "current accuracy on test set:  0.8593776282590412\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 44 j: 0 Elapsed Time(m): 4.00\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0003  \n",
      "current accuracy on test set:  0.8612279226240538\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 45 j: 0 Elapsed Time(m): 4.09\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0003  \n",
      "current accuracy on test set:  0.8612279226240538\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 45 j: 1 Elapsed Time(m): 4.18\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0000  \n",
      "current accuracy on test set:  0.8610597140454164\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 45 j: 2 Elapsed Time(m): 4.27\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0000  \n",
      "current accuracy on test set:  0.8603868797308662\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 45 j: 3 Elapsed Time(m): 4.36\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0000  \n",
      "current accuracy on test set:  0.8602186711522287\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 45 j: 4 Elapsed Time(m): 4.45\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0000  \n",
      "current accuracy on test set:  0.8603868797308662\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 45 j: 5 Elapsed Time(m): 4.54\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0000  \n",
      "current accuracy on test set:  0.8605550883095038\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 45 j: 6 Elapsed Time(m): 4.63\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0000  \n",
      "current accuracy on test set:  0.8603868797308662\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 45 j: 7 Elapsed Time(m): 4.72\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0000  \n",
      "current accuracy on test set:  0.8603868797308662\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 45 j: 8 Elapsed Time(m): 4.81\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0000  \n",
      "current accuracy on test set:  0.8603868797308662\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 45 j: 9 Elapsed Time(m): 4.90\n",
      "epoch: 1/1 ETA: 0:02 loss: 0.0000  \n",
      "current accuracy on test set:  0.8603868797308662\n"
     ]
    }
   ],
   "source": [
    "DA(tsolver,src_data,src_gts,trg_data,trg_cp,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T15:48:04.587299Z",
     "start_time": "2020-11-12T15:48:03.737265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set before domain adaptation:  0.7530698065601346\n",
      "Accuracy on test set after domain adaptation:  0.8603868797308662\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on test set before domain adaptation: ',only_src_acc)\n",
    "DA_acc = test(x_test,y_test,tsolver)\n",
    "print('Accuracy on test set after domain adaptation: ',DA_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "494.667px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
