{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T14:43:23.447413Z",
     "start_time": "2020-11-13T14:43:23.440365Z"
    }
   },
   "outputs": [],
   "source": [
    "# Path to the MDS dataset\n",
    "dataset_path='../datasets/CICIDS2017_packet-based/' \n",
    "\n",
    "#### all_domains = ['tuesday','wednesday','thursday']\n",
    "#### src_domain and trg_domain can be any of the above domains.\n",
    "s_domain = 'thursday' #source domain\n",
    "t_domain = 'tuesday' #target domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T14:43:25.487469Z",
     "start_time": "2020-11-13T14:43:24.005179Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys,os\n",
    "#### Change \"0\" to GPU device number you want to use if you have multiple GPU devices\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] =\"1\" \n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from aux_functions import  preproces_dataset, Solver, PacketModel, DataHandler\n",
    "from sklearn import metrics\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# plt.rcParams['image.interpolation'] = 'nearest'\n",
    "# plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T14:43:30.867426Z",
     "start_time": "2020-11-13T14:43:25.488833Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../datasets/CICIDS2017_packet-based/thursday/part_00000.npy\n",
      "../datasets/CICIDS2017_packet-based/thursday/part_00001.npy\n",
      "../datasets/CICIDS2017_packet-based/thursday/part_00002.npy\n",
      "../datasets/CICIDS2017_packet-based/thursday/part_00003.npy\n",
      "../datasets/CICIDS2017_packet-based/thursday/part_00004.npy\n",
      "../datasets/CICIDS2017_packet-based/thursday/part_00005.npy\n",
      "../datasets/CICIDS2017_packet-based/thursday/part_00006.npy\n",
      "../datasets/CICIDS2017_packet-based/thursday/part_00007.npy\n",
      "../datasets/CICIDS2017_packet-based/thursday/part_00008.npy\n",
      "../datasets/CICIDS2017_packet-based/thursday/part_00009.npy\n",
      "../datasets/CICIDS2017_packet-based/thursday/part_00010.npy\n",
      "../datasets/CICIDS2017_packet-based/thursday/part_00011.npy\n",
      "../datasets/CICIDS2017_packet-based/thursday/part_00012.npy\n",
      "../datasets/CICIDS2017_packet-based/thursday/part_00013.npy\n",
      "../datasets/CICIDS2017_packet-based/thursday/part_00014.npy\n",
      "../datasets/CICIDS2017_packet-based/thursday/part_00015.npy\n",
      "../datasets/CICIDS2017_packet-based/thursday/part_00016.npy\n",
      "../datasets/CICIDS2017_packet-based/thursday/part_00017.npy\n",
      "../datasets/CICIDS2017_packet-based/thursday/part_00018.npy\n",
      "../datasets/CICIDS2017_packet-based/thursday/part_00019.npy\n",
      "../datasets/CICIDS2017_packet-based/tuesday/part_00000.npy\n",
      "../datasets/CICIDS2017_packet-based/tuesday/part_00001.npy\n",
      "../datasets/CICIDS2017_packet-based/tuesday/part_00002.npy\n",
      "../datasets/CICIDS2017_packet-based/tuesday/part_00003.npy\n",
      "../datasets/CICIDS2017_packet-based/tuesday/part_00004.npy\n",
      "../datasets/CICIDS2017_packet-based/tuesday/part_00005.npy\n",
      "../datasets/CICIDS2017_packet-based/tuesday/part_00006.npy\n",
      "../datasets/CICIDS2017_packet-based/tuesday/part_00007.npy\n",
      "../datasets/CICIDS2017_packet-based/tuesday/part_00008.npy\n",
      "../datasets/CICIDS2017_packet-based/tuesday/part_00009.npy\n",
      "../datasets/CICIDS2017_packet-based/tuesday/part_00010.npy\n",
      "../datasets/CICIDS2017_packet-based/tuesday/part_00011.npy\n",
      "../datasets/CICIDS2017_packet-based/tuesday/part_00012.npy\n",
      "../datasets/CICIDS2017_packet-based/tuesday/part_00013.npy\n",
      "../datasets/CICIDS2017_packet-based/tuesday/part_00014.npy\n",
      "../datasets/CICIDS2017_packet-based/tuesday/part_00015.npy\n",
      "../datasets/CICIDS2017_packet-based/tuesday/part_00016.npy\n",
      "../datasets/CICIDS2017_packet-based/tuesday/part_00017.npy\n",
      "../datasets/CICIDS2017_packet-based/tuesday/part_00018.npy\n",
      "../datasets/CICIDS2017_packet-based/tuesday/part_00019.npy\n",
      "../datasets/CICIDS2017_packet-based/tuesday/part_00020.npy\n",
      "../datasets/CICIDS2017_packet-based/tuesday/part_00021.npy\n",
      "../datasets/CICIDS2017_packet-based/tuesday/part_00022.npy\n",
      "../datasets/CICIDS2017_packet-based/tuesday/part_00023.npy\n",
      "x_src.shape: (462031, 580) y_src.shape: (462031,) x_trg.shape: (573544, 580) y_trg.shape: (573544,)\n",
      "Malicious ratio in the source domain: 0.027026325073425807\n",
      "Malicious ratio in the target domain: 0.021738523984210452\n"
     ]
    }
   ],
   "source": [
    "x_src,y_src,x_trg,y_trg,train_min,train_max = preproces_dataset(s_domain,t_domain,dataset_path)\n",
    "\n",
    "##### Uncomment the next two lines to make the training procedure faster!\n",
    "# x_trg = x_trg[::2]\n",
    "# y_trg = y_trg[::2]\n",
    "\n",
    "y_src_onehot = np.zeros((len(y_src),2),np.float32)\n",
    "y_src_onehot[range(len(y_src)),y_src.astype(np.int32)] = 1.\n",
    "\n",
    "y_trg_onehot = np.zeros((len(y_trg),2),np.float32)\n",
    "y_trg_onehot[range(len(y_trg)),y_trg.astype(np.int32)] = 1.\n",
    "\n",
    "print('x_src.shape:',x_src.shape,'y_src.shape:',y_src.shape,'x_trg.shape:',x_trg.shape,'y_trg.shape:',y_trg.shape)\n",
    "print('Malicious ratio in the source domain:',np.sum(y_src==1)/len(y_src))\n",
    "print('Malicious ratio in the target domain:',np.sum(y_trg==1)/len(y_trg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a model on the src domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T14:43:31.719703Z",
     "start_time": "2020-11-13T14:43:30.869530Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method PacketModel.call of <aux_functions.PacketModel object at 0x7fc1d6207050>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <bound method PacketModel.call of <aux_functions.PacketModel object at 0x7fc1d6207050>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "input_size = x_src.shape[1]\n",
    "net = PacketModel()\n",
    "net._set_inputs(tf.TensorSpec([None,input_size]))\n",
    "\n",
    "base_lr = 0.0001\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=base_lr)\n",
    "grads = []\n",
    "for v in net.trainable_variables:\n",
    "    grads.append(np.zeros(v.shape))\n",
    "optimizer.apply_gradients(zip(grads,net.trainable_variables))\n",
    "\n",
    "tsolver = Solver(optimizer,net,base_lr)\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T14:43:31.745155Z",
     "start_time": "2020-11-13T14:43:31.721236Z"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(x, y, optimizer,net):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = net(x, training=True)\n",
    "        mse_loss = tf.reduce_sum((y - y_pred)**2,axis=1)\n",
    "        mse_loss = tf.reduce_mean(mse_loss)\n",
    "    gradients = tape.gradient(mse_loss, net.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, net.trainable_variables))\n",
    "    train_loss(mse_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T14:43:31.832527Z",
     "start_time": "2020-11-13T14:43:31.746288Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model_on_src(nb_iters,dhandler,tsolver):\n",
    "    st = time.time()\n",
    "    train_loss.reset_states()\n",
    "    for i in range(nb_iters):\n",
    "        x_batch,y_batch = dhandler.next_batch()\n",
    "\n",
    "        if i%5==0:\n",
    "            tsolver.iters+=1\n",
    "            tsolver.update_lr()\n",
    "\n",
    "        train_step(x_batch,y_batch,tsolver.optimizer,tsolver.net)\n",
    "        if i % 50 == 49 or i == nb_iters - 1:\n",
    "            remained_iters = nb_iters - i\n",
    "            passed_time = time.time() - st\n",
    "            ETA = int(passed_time * remained_iters / i)\n",
    "            ETA_min, ETA_sec = ETA // 60, ETA % 60\n",
    "            mean_loss = train_loss.result().numpy()\n",
    "            print ('\\r' + \\\n",
    "                  ' iter: ' + str(i + 1) + '/' + str(nb_iters) + \\\n",
    "                  ' ETA: ' + str(ETA_min) + ':' + \"{0:02d}\".format(ETA_sec) + \\\n",
    "                  ' loss: ' + \"{0:0.4f}\".format(mean_loss),end=\" \")\n",
    "            sys.stdout.flush()\n",
    "    print(' ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T14:43:48.663230Z",
     "start_time": "2020-11-13T14:43:33.282255Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function train_step at 0x7fc24afb6710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Str'\n",
      "WARNING: AutoGraph could not transform <function train_step at 0x7fc24afb6710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Str'\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method PacketModel.call of <aux_functions.PacketModel object at 0x7fc1d6207050>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <bound method PacketModel.call of <aux_functions.PacketModel object at 0x7fc1d6207050>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      " iter: 1805/1805 ETA: 0:00 loss: 0.0500  \n",
      " iter: 1805/1805 ETA: 0:00 loss: 0.0200  \n",
      " iter: 1805/1805 ETA: 0:00 loss: 0.0148  \n",
      " iter: 1805/1805 ETA: 0:00 loss: 0.0136  \n",
      " iter: 1805/1805 ETA: 0:00 loss: 0.0118  \n",
      " iter: 1805/1805 ETA: 0:00 loss: 0.0118  \n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 6\n",
    "batch_size = 256\n",
    "total_batch = len(x_src)//batch_size\n",
    "if len(x_src) % batch_size!=0:\n",
    "    total_batch+=1\n",
    "\n",
    "for i in range(nb_epochs):\n",
    "    ##### balancing dataset\n",
    "    pos_inds = y_src==1\n",
    "    x_src_pos = x_src[pos_inds]\n",
    "    y_src_pos = y_src_onehot[pos_inds]\n",
    "    x_src_neg = x_src[~pos_inds]\n",
    "    y_src_neg = y_src_onehot[~pos_inds]\n",
    "    p = np.random.permutation(len(x_src_neg))\n",
    "    x_src_neg = x_src_neg[p]\n",
    "    y_src_neg = y_src_neg[p]\n",
    "    pos_len = len(x_src_pos)\n",
    "\n",
    "    src_dhandler = DataHandler(np.concatenate((x_src_pos,x_src_neg[:pos_len]))\n",
    "                                       ,np.concatenate((y_src_pos,y_src_neg[:pos_len])),None,batch_size=256,shuffle=True)\n",
    "\n",
    "    train_model_on_src(total_batch,src_dhandler,tsolver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T14:43:48.700647Z",
     "start_time": "2020-11-13T14:43:48.665419Z"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(x,net):\n",
    "    return net(x,training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T14:43:48.806900Z",
     "start_time": "2020-11-13T14:43:48.704813Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_outputs(x_ds,y_ds,net,ret_logits=False):\n",
    "    all_y_pred = np.zeros_like(y_ds)\n",
    "    all_scores = np.zeros((len(y_ds),2))\n",
    "    for i in range(0,len(x_ds),batch_size):\n",
    "        x_batch = x_ds[i:i+batch_size]\n",
    "        y_batch = y_ds[i:i+batch_size]\n",
    "        y_pred = test_step(x_batch,net)\n",
    "        y_pred = y_pred.numpy()\n",
    "        all_scores[i:i+batch_size] = y_pred\n",
    "        y_pred = y_pred.argmax(axis=1)\n",
    "        all_y_pred[i:i+batch_size] = y_pred\n",
    "    if ret_logits:\n",
    "        return all_scores\n",
    "    \n",
    "    return all_y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T14:43:48.922090Z",
     "start_time": "2020-11-13T14:43:48.811811Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_f1_score(x_ds,y_ds):\n",
    "    all_y_pred = get_outputs(x_ds,y_ds,net)\n",
    "    f1_score = metrics.f1_score(y_true=y_ds,y_pred=all_y_pred)\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T14:43:51.545090Z",
     "start_time": "2020-11-13T14:43:48.924281Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function test_step at 0x7fc1d6527b00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function test_step at 0x7fc1d6527b00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method PacketModel.call of <aux_functions.PacketModel object at 0x7fc1d6207050>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <bound method PacketModel.call of <aux_functions.PacketModel object at 0x7fc1d6207050>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method PacketModel.call of <aux_functions.PacketModel object at 0x7fc1d6207050>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <bound method PacketModel.call of <aux_functions.PacketModel object at 0x7fc1d6207050>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "F1 score on the trg domain: 0.009241210020937116\n"
     ]
    }
   ],
   "source": [
    "only_src_f1_score = calc_f1_score(x_trg,y_trg)\n",
    "print('F1 score on the trg domain:',only_src_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Domain Adaptation with PPPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T14:43:51.597737Z",
     "start_time": "2020-11-13T14:43:51.547203Z"
    }
   },
   "outputs": [],
   "source": [
    "base_lr = 0.0001\n",
    "optimizer = tf.keras.optimizers.Adam(lr=base_lr)\n",
    "grads = []\n",
    "for v in net.trainable_variables:\n",
    "    grads.append(np.zeros(v.shape))\n",
    "optimizer.apply_gradients(zip(grads,net.trainable_variables))\n",
    "\n",
    "tsolver = Solver(optimizer,net,base_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T14:43:51.676125Z",
     "start_time": "2020-11-13T14:43:51.598950Z"
    }
   },
   "outputs": [],
   "source": [
    "trg_gts = y_trg\n",
    "trg_data = x_trg\n",
    "src_gts = y_src\n",
    "src_data = x_src\n",
    "t_labels = np.array(trg_gts)\n",
    "\n",
    "n_classes = 2\n",
    "trg_cp = np.zeros(n_classes)\n",
    "for i in range(n_classes):\n",
    "    trg_cp[i] = np.sum(t_labels==i)/len(t_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T14:43:51.757402Z",
     "start_time": "2020-11-13T14:43:51.679166Z"
    }
   },
   "outputs": [],
   "source": [
    "def adjust_pseudo_labels(trg_probs_np,trg_cp):\n",
    "    n_classes = 2\n",
    "    pseudo_labels = trg_probs_np.argmax(axis=1)\n",
    "    current_cp = np.zeros(n_classes)\n",
    "    for c in range(n_classes):\n",
    "        current_cp[c] = np.sum(pseudo_labels==c)/len(trg_probs_np)\n",
    "\n",
    "    diff_class_rates =  current_cp - trg_cp\n",
    "    for i in range(len(diff_class_rates)):\n",
    "        if diff_class_rates[i]<=0:\n",
    "            continue\n",
    "        predicted_as_c = pseudo_labels==i\n",
    "        current_class = i\n",
    "        current_diff = diff_class_rates[i]\n",
    "        current_num = np.round(current_diff*len(trg_probs_np)).astype(np.int32)\n",
    "\n",
    "        current_probs = trg_probs_np[pseudo_labels==current_class]\n",
    "        current_probs_sorted = np.sort(current_probs,axis=1)\n",
    "        current_certainty_scores = current_probs_sorted[:,-1] - current_probs_sorted[:,-2]\n",
    "        \n",
    "        current_certainty_scores_sorted_inds = np.argsort(current_certainty_scores)\n",
    "        y_val = np.ones(len(current_certainty_scores))*current_class\n",
    "        for j in range(current_num):\n",
    "            y_val[j]=1-current_class ###change pseudo-label to the opposite class!\n",
    "#             y_val[j]=-1\n",
    "        temp_pl = np.zeros(len(current_certainty_scores))\n",
    "        temp_pl[current_certainty_scores_sorted_inds] = y_val\n",
    "        pseudo_labels[predicted_as_c] = temp_pl\n",
    "    \n",
    "    return pseudo_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T14:43:51.881878Z",
     "start_time": "2020-11-13T14:43:51.762265Z"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step_DA(x, y, w, optimizer,net):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = net(x, training=True)\n",
    "        mse_loss = tf.reduce_sum((y - y_pred)**2,axis=1)*w\n",
    "        mse_loss = tf.reduce_mean(mse_loss)\n",
    "    gradients = tape.gradient(mse_loss, net.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, net.trainable_variables))\n",
    "    train_loss(mse_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T14:43:51.951969Z",
     "start_time": "2020-11-13T14:43:51.883325Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model_with_weights(nb_epochs,dhandler,tsolver):\n",
    "    total_batch = dhandler.len // dhandler.batch_size\n",
    "    if dhandler.len % dhandler.batch_size != 0:\n",
    "        total_batch += 1\n",
    "    st = time.time()\n",
    "    for ep in range(nb_epochs):\n",
    "        train_loss.reset_states()\n",
    "        for i in range(total_batch):\n",
    "            x_batch,y_batch_t,w_batch = dhandler.next_batch()\n",
    "            y_batch = np.zeros((dhandler.batch_size,2),dtype=np.float32)\n",
    "            y_batch[range(dhandler.batch_size),y_batch_t] = 1\n",
    "            train_step_DA(x_batch,y_batch,w_batch,tsolver.optimizer,tsolver.net)\n",
    "\n",
    "        passed_time = time.time() - st\n",
    "        remained_epochs = nb_epochs - ep\n",
    "        ETA = int(passed_time * remained_epochs)\n",
    "        ETA_min, ETA_sec = ETA // 60, ETA % 60\n",
    "        print ('\\r' + 'epoch: ' + str(ep + 1) + '/' + str(nb_epochs) + \\\n",
    "                      ' ETA: ' + str(ETA_min) + ':' + \"{0:02d}\".format(ETA_sec) + \\\n",
    "                      ' loss: ' + \"{0:0.4f}\".format(train_loss.result().numpy()),end=\" \")\n",
    "        sys.stdout.flush()\n",
    "    print(' ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T14:43:52.075431Z",
     "start_time": "2020-11-13T14:43:51.953807Z"
    }
   },
   "outputs": [],
   "source": [
    "def DA(tsolver,src_data,src_gts,trg_data,trg_cp,trg_gts):\n",
    "    #### Target labels are not used during training. We only use them for calculating f1 scores.\n",
    "    begin_time = time.time()\n",
    "    inner_loop_size = 1\n",
    "    trg_gts_unreal = np.zeros(len(trg_data))\n",
    "    weights_src = np.ones(len(src_gts))\n",
    "    \n",
    "    for nnn in range(0,90,2):\n",
    "        if nnn>=88:\n",
    "            inner_loop_size=10\n",
    "        for j in range(inner_loop_size):\n",
    "            print ('^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i:',nnn//2 + 1,'j:',j,\n",
    "               'Elapsed Time(m): {0:0.2f}'.format((time.time()-begin_time)/60))\n",
    "            \n",
    "\n",
    "            #### Get scores on the target domain\n",
    "            trg_scores_np = get_outputs(trg_data,trg_gts_unreal,net,ret_logits=True)\n",
    "            \n",
    "            #### Calculate pseudo-labels of the target domain\n",
    "            trg_pseudo_labels = trg_scores_np.argmax(axis=1)\n",
    "            \n",
    "            trg_pseudo_labels_adjusted = adjust_pseudo_labels(np.copy(trg_scores_np),trg_cp)\n",
    "            if nnn<60:\n",
    "                ### for the first 30 iterations instead of exclusion of samples \n",
    "                ### that their CP is larger than expected CP we change their pseudo-label\n",
    "                ### to the oposite class and keep them into the training set!\n",
    "                trg_pseudo_labels = trg_pseudo_labels_adjusted\n",
    "            \n",
    "            ### Calculate the certainty scores for target samples\n",
    "            trg_scores_np_sorted = np.sort(trg_scores_np,axis=1)\n",
    "            certainty_scores = trg_scores_np_sorted[:,-1] - trg_scores_np_sorted[:,-2]\n",
    "            \n",
    "            ### Calculate weight for the target samples\n",
    "            weights_trg = np.zeros(len(certainty_scores))\n",
    "            for c in range(n_classes):\n",
    "                predicted_as_c = trg_pseudo_labels==c\n",
    "                size_c = np.sum(predicted_as_c)\n",
    "                if size_c>1:\n",
    "                    left_size = int(np.ceil(((nnn+1)*0.01+0.1)*size_c))\n",
    "                    x_val_left = 1+(10/2 - 1)/left_size*(np.arange(left_size))\n",
    "                    right_size = size_c - left_size\n",
    "                    x_val_right = 10000*(np.arange(1,right_size+1))\n",
    "                    x_val = np.concatenate((x_val_left,x_val_right))\n",
    "                    y_val = np.power(x_val,-1)\n",
    "                    y_val = y_val[::-1]\n",
    "\n",
    "                    cs_c = certainty_scores[predicted_as_c]\n",
    "                    cs_c_sorted_inds = np.argsort(cs_c)\n",
    "                    weights_trg2 = np.zeros(len(cs_c))\n",
    "                    weights_trg2[cs_c_sorted_inds] = y_val\n",
    "                    weights_trg[predicted_as_c] = weights_trg2\n",
    "                    \n",
    "            ### Exclude\n",
    "            coef = (trg_pseudo_labels==trg_pseudo_labels_adjusted)*1\n",
    "            weights_trg*=coef\n",
    "            inclusion_condition = weights_trg>=0.001\n",
    "            trg_samples = trg_data[inclusion_condition]\n",
    "            trg_pseudo_labels = trg_pseudo_labels[inclusion_condition].astype(np.int32)\n",
    "            weights_trg = weights_trg[inclusion_condition]\n",
    "\n",
    "\n",
    "            #### Randomly select some samples from the source domain\n",
    "            p = np.random.permutation(len(src_data))\n",
    "            p = p[:len(trg_data)]\n",
    "            x_temp = src_data[p]\n",
    "            y_temp = src_gts[p]\n",
    "            w_temp = weights_src[:len(trg_data)]\n",
    "\n",
    "            #### Train Model\n",
    "            m1 = np.concatenate((x_temp,trg_samples))\n",
    "            m2 = np.concatenate((y_temp,trg_pseudo_labels)).astype(np.int32)\n",
    "            m3 = np.concatenate((w_temp,weights_trg)).astype(np.float32)\n",
    "            \n",
    "                                        \n",
    "            if nnn<60:\n",
    "                ### Balancing the positive and negative samples\n",
    "                pos_inds = m2==1\n",
    "                x_train_pos = m1[pos_inds]\n",
    "                y_train_pos = m2[pos_inds]\n",
    "                w_train_pos = m3[pos_inds]\n",
    "                x_train_neg = m1[~pos_inds]\n",
    "                y_train_neg = m2[~pos_inds]\n",
    "                w_train_neg = m3[~pos_inds]\n",
    "                p = np.random.permutation(len(x_train_neg))\n",
    "                x_train_neg = x_train_neg[p]\n",
    "                y_train_neg = y_train_neg[p]\n",
    "                w_train_neg = w_train_neg[p]\n",
    "                pos_len = len(x_train_pos)\n",
    "\n",
    "                DA_dhandler = DataHandler(np.concatenate((x_train_pos,x_train_neg[:pos_len]))\n",
    "                                                   ,np.concatenate((y_train_pos,y_train_neg[:pos_len]))\n",
    "                                              ,np.concatenate((w_train_pos,w_train_neg[:pos_len])),batch_size=256,shuffle=True)\n",
    "\n",
    "            else:\n",
    "                DA_dhandler = DataHandler(m1, m2, m3, 256,shuffle=True)                \n",
    "\n",
    "            ep = 1\n",
    "            train_model_with_weights(ep,DA_dhandler,tsolver)\n",
    "\n",
    "            if nnn%8==0:\n",
    "                current_f1 = calc_f1_score(trg_data,trg_gts)\n",
    "                print('Current F1 score on the trg domain:',current_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T14:50:27.840229Z",
     "start_time": "2020-11-13T14:43:52.076676Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 1 j: 0 Elapsed Time(m): 0.00\n",
      "WARNING:tensorflow:AutoGraph could not transform <function train_step_DA at 0x7fc1d4234a70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Str'\n",
      "WARNING: AutoGraph could not transform <function train_step_DA at 0x7fc1d4234a70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Str'\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method PacketModel.call of <aux_functions.PacketModel object at 0x7fc1d6207050>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <bound method PacketModel.call of <aux_functions.PacketModel object at 0x7fc1d6207050>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "epoch: 1/1 ETA: 0:00 loss: 0.0326  \n",
      "Current F1 score on the trg domain: 0.09166000532907008\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 2 j: 0 Elapsed Time(m): 0.10\n",
      "epoch: 1/1 ETA: 0:00 loss: 0.0263  \n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 3 j: 0 Elapsed Time(m): 0.16\n",
      "epoch: 1/1 ETA: 0:00 loss: 0.0195  \n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 4 j: 0 Elapsed Time(m): 0.22\n",
      "epoch: 1/1 ETA: 0:00 loss: 0.0184  \n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 5 j: 0 Elapsed Time(m): 0.27\n",
      "epoch: 1/1 ETA: 0:00 loss: 0.0188  \n",
      "Current F1 score on the trg domain: 0.3788405317447184\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 6 j: 0 Elapsed Time(m): 0.37\n",
      "epoch: 1/1 ETA: 0:00 loss: 0.0163  \n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 7 j: 0 Elapsed Time(m): 0.43\n",
      "epoch: 1/1 ETA: 0:00 loss: 0.0154  \n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 8 j: 0 Elapsed Time(m): 0.49\n",
      "epoch: 1/1 ETA: 0:00 loss: 0.0165  \n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 9 j: 0 Elapsed Time(m): 0.54\n",
      "epoch: 1/1 ETA: 0:00 loss: 0.0145  \n",
      "Current F1 score on the trg domain: 0.5707007549441896\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 10 j: 0 Elapsed Time(m): 0.64\n",
      "epoch: 1/1 ETA: 0:00 loss: 0.0149  \n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 11 j: 0 Elapsed Time(m): 0.70\n",
      "epoch: 1/1 ETA: 0:00 loss: 0.0144  \n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 12 j: 0 Elapsed Time(m): 0.76\n",
      "epoch: 1/1 ETA: 0:00 loss: 0.0150  \n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 13 j: 0 Elapsed Time(m): 0.82\n",
      "epoch: 1/1 ETA: 0:00 loss: 0.0138  \n",
      "Current F1 score on the trg domain: 0.6483817882611081\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 14 j: 0 Elapsed Time(m): 0.92\n",
      "epoch: 1/1 ETA: 0:00 loss: 0.0136  \n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 15 j: 0 Elapsed Time(m): 0.99\n",
      "epoch: 1/1 ETA: 0:00 loss: 0.0132  \n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 16 j: 0 Elapsed Time(m): 1.05\n",
      "epoch: 1/1 ETA: 0:00 loss: 0.0120  \n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 17 j: 0 Elapsed Time(m): 1.12\n",
      "epoch: 1/1 ETA: 0:00 loss: 0.0110  \n",
      "Current F1 score on the trg domain: 0.7307095387798956\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 18 j: 0 Elapsed Time(m): 1.24\n",
      "epoch: 1/1 ETA: 0:00 loss: 0.0123  \n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 19 j: 0 Elapsed Time(m): 1.31\n",
      "epoch: 1/1 ETA: 0:00 loss: 0.0129  \n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 20 j: 0 Elapsed Time(m): 1.39\n",
      "epoch: 1/1 ETA: 0:00 loss: 0.0122  \n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 21 j: 0 Elapsed Time(m): 1.47\n",
      "epoch: 1/1 ETA: 0:00 loss: 0.0115  \n",
      "Current F1 score on the trg domain: 0.7453144084572295\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 22 j: 0 Elapsed Time(m): 1.59\n",
      "epoch: 1/1 ETA: 0:00 loss: 0.0111  \n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 23 j: 0 Elapsed Time(m): 1.68\n",
      "epoch: 1/1 ETA: 0:00 loss: 0.0100  \n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 24 j: 0 Elapsed Time(m): 1.76\n",
      "epoch: 1/1 ETA: 0:00 loss: 0.0115  \n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 25 j: 0 Elapsed Time(m): 1.85\n",
      "epoch: 1/1 ETA: 0:00 loss: 0.0104  \n",
      "Current F1 score on the trg domain: 0.7639584454285832\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 26 j: 0 Elapsed Time(m): 1.98\n",
      "epoch: 1/1 ETA: 0:00 loss: 0.0116  \n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 27 j: 0 Elapsed Time(m): 2.07\n",
      "epoch: 1/1 ETA: 0:00 loss: 0.0101  \n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 28 j: 0 Elapsed Time(m): 2.17\n",
      "epoch: 1/1 ETA: 0:00 loss: 0.0101  \n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 29 j: 0 Elapsed Time(m): 2.26\n",
      "epoch: 1/1 ETA: 0:00 loss: 0.0106  \n",
      "Current F1 score on the trg domain: 0.7825415532165644\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 30 j: 0 Elapsed Time(m): 2.40\n",
      "epoch: 1/1 ETA: 0:00 loss: 0.0103  \n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 31 j: 0 Elapsed Time(m): 2.50\n",
      "epoch: 1/1 ETA: 0:04 loss: 0.0083  \n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 32 j: 0 Elapsed Time(m): 2.64\n",
      "epoch: 1/1 ETA: 0:04 loss: 0.0066  \n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 33 j: 0 Elapsed Time(m): 2.77\n",
      "epoch: 1/1 ETA: 0:04 loss: 0.0059  \n",
      "Current F1 score on the trg domain: 0.737471393209098\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 34 j: 0 Elapsed Time(m): 2.95\n",
      "epoch: 1/1 ETA: 0:04 loss: 0.0055  \n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 35 j: 0 Elapsed Time(m): 3.09\n",
      "epoch: 1/1 ETA: 0:04 loss: 0.0051  \n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 36 j: 0 Elapsed Time(m): 3.23\n",
      "epoch: 1/1 ETA: 0:04 loss: 0.0048  \n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 37 j: 0 Elapsed Time(m): 3.38\n",
      "epoch: 1/1 ETA: 0:04 loss: 0.0046  \n",
      "Current F1 score on the trg domain: 0.7304785894206548\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 38 j: 0 Elapsed Time(m): 3.56\n",
      "epoch: 1/1 ETA: 0:04 loss: 0.0044  \n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 39 j: 0 Elapsed Time(m): 3.71\n",
      "epoch: 1/1 ETA: 0:04 loss: 0.0042  \n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 40 j: 0 Elapsed Time(m): 3.85\n",
      "epoch: 1/1 ETA: 0:04 loss: 0.0040  \n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 41 j: 0 Elapsed Time(m): 4.01\n",
      "epoch: 1/1 ETA: 0:04 loss: 0.0038  \n",
      "Current F1 score on the trg domain: 0.7594536839171235\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 42 j: 0 Elapsed Time(m): 4.20\n",
      "epoch: 1/1 ETA: 0:04 loss: 0.0037  \n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 43 j: 0 Elapsed Time(m): 4.36\n",
      "epoch: 1/1 ETA: 0:04 loss: 0.0036  \n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 44 j: 0 Elapsed Time(m): 4.51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/1 ETA: 0:04 loss: 0.0035  \n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 45 j: 0 Elapsed Time(m): 4.67\n",
      "epoch: 1/1 ETA: 0:04 loss: 0.0034  \n",
      "Current F1 score on the trg domain: 0.7787311729803742\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 45 j: 1 Elapsed Time(m): 4.87\n",
      "epoch: 1/1 ETA: 0:04 loss: 0.0033  \n",
      "Current F1 score on the trg domain: 0.7733883918329892\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 45 j: 2 Elapsed Time(m): 5.07\n",
      "epoch: 1/1 ETA: 0:04 loss: 0.0032  \n",
      "Current F1 score on the trg domain: 0.7763326616596447\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 45 j: 3 Elapsed Time(m): 5.28\n",
      "epoch: 1/1 ETA: 0:04 loss: 0.0031  \n",
      "Current F1 score on the trg domain: 0.7796471070988922\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 45 j: 4 Elapsed Time(m): 5.48\n",
      "epoch: 1/1 ETA: 0:04 loss: 0.0030  \n",
      "Current F1 score on the trg domain: 0.7803410230692076\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 45 j: 5 Elapsed Time(m): 5.66\n",
      "epoch: 1/1 ETA: 0:04 loss: 0.0030  \n",
      "Current F1 score on the trg domain: 0.7884267631103073\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 45 j: 6 Elapsed Time(m): 5.85\n",
      "epoch: 1/1 ETA: 0:04 loss: 0.0029  \n",
      "Current F1 score on the trg domain: 0.7915557760837205\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 45 j: 7 Elapsed Time(m): 6.03\n",
      "epoch: 1/1 ETA: 0:04 loss: 0.0028  \n",
      "Current F1 score on the trg domain: 0.7950495049504951\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 45 j: 8 Elapsed Time(m): 6.22\n",
      "epoch: 1/1 ETA: 0:04 loss: 0.0028  \n",
      "Current F1 score on the trg domain: 0.7941890797877125\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 45 j: 9 Elapsed Time(m): 6.41\n",
      "epoch: 1/1 ETA: 0:04 loss: 0.0027  \n",
      "Current F1 score on the trg domain: 0.7950746000359519\n"
     ]
    }
   ],
   "source": [
    "DA(tsolver,src_data,src_gts,trg_data,trg_cp,trg_gts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T14:50:30.191431Z",
     "start_time": "2020-11-13T14:50:27.841993Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current F1 score on the trg domain: 0.7950746000359519\n"
     ]
    }
   ],
   "source": [
    "current_f1 = calc_f1_score(trg_data,trg_gts)\n",
    "print('Current F1 score on the trg domain:',current_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "412.222px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
